# Image Caption Generator
This repository contains an implementation of an Image Caption Generator web application that uses a pre-trained CNN (ResNet-152) encoder and RNN decoder architecture to generate descriptive captions for images. The CNN based ResNet-152 encoder extracts deep visual features from images and the RNN decoder translates these features into human-readable captions. The model was trained on a subset of [COCO "Common Objects in Context" dataset](https://cocodataset.org/#home), known for its rich variety of image-caption pairs of 80 object categories, and at least five textual reference captions per image.

# Demo
https://github.com/sayan97/image-caption-generator/blob/main/demo.mp4
